#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
o4-miniæ¨¡å‹é…ç½®æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨é…ç½®çš„o4-miniæ¨¡å‹è¿›è¡Œå®‰å…¨åˆ†æ
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent / "src" / "backend"))

from config.openai_config import (
    OpenAIConfig,
    ModelType,
    AnalysisComplexity,
    ModelConfig
)

def print_separator(title: str):
    """æ‰“å°åˆ†éš”ç¬¦"""
    print("\n" + "=" * 60)
    print(f" {title} ")
    print("=" * 60)

def demo_o4_mini_configuration():
    """æ¼”ç¤ºo4-miniæ¨¡å‹é…ç½®"""
    print_separator("o4-miniæ¨¡å‹é…ç½®æ¼”ç¤º")
    
    # åˆ›å»ºOpenAIé…ç½®å®ä¾‹
    config = OpenAIConfig()
    
    print("ğŸ“‹ å½“å‰æ¨¡å‹é…ç½®:")
    print(f"é»˜è®¤æ¨¡å‹: {config.default_model.model_type.value}")
    print(f"æœ€å¤§Tokenæ•°: {config.default_model.max_tokens}")
    print(f"æ¸©åº¦å‚æ•°: {config.default_model.temperature}")
    
    print("\nğŸ¯ å„å¤æ‚åº¦çº§åˆ«çš„æ¨¡å‹é…ç½®:")
    for complexity in AnalysisComplexity:
        model_config = config.get_model_config(complexity)
        print(f"  {complexity.value:12}: {model_config.model_type.value:15} (max_tokens: {model_config.max_tokens:4}, temp: {model_config.temperature})")
    
    print("\nâœ¨ o4-miniæ¨¡å‹çš„ä¼˜åŠ¿:")
    print("  â€¢ æ›´å¿«çš„å“åº”é€Ÿåº¦")
    print("  â€¢ æ›´ä½çš„ä½¿ç”¨æˆæœ¬")
    print("  â€¢ ä¼˜ç§€çš„æ¨ç†èƒ½åŠ›")
    print("  â€¢ é€‚åˆç®€å•å’Œæ ‡å‡†åˆ†æä»»åŠ¡")
    
    print("\nğŸ”§ æ¨¡å‹é€‰æ‹©ç­–ç•¥:")
    print("  â€¢ ç®€å•åˆ†æ (simple): o4-mini - å¿«é€ŸåŸºç¡€åˆ†æ")
    print("  â€¢ æ ‡å‡†åˆ†æ (standard): o4-mini - æ—¥å¸¸å®‰å…¨åˆ†æ")
    print("  â€¢ è¯¦ç»†åˆ†æ (detailed): GPT-4 - å¤æ‚å¨èƒåˆ†æ")
    print("  â€¢ å…¨é¢åˆ†æ (comprehensive): GPT-4-32K - å¤§è§„æ¨¡äº‹ä»¶åˆ†æ")

def demo_model_type_enum():
    """æ¼”ç¤ºæ¨¡å‹ç±»å‹æšä¸¾"""
    print_separator("æ”¯æŒçš„æ¨¡å‹ç±»å‹")
    
    print("ğŸ¤– å½“å‰æ”¯æŒçš„æ¨¡å‹:")
    for model_type in ModelType:
        print(f"  â€¢ {model_type.name:15}: {model_type.value}")
    
    print("\nğŸ†• æ–°å¢çš„o4-miniæ¨¡å‹:")
    print(f"  æ¨¡å‹åç§°: {ModelType.GPT_4O_MINI.name}")
    print(f"  æ¨¡å‹å€¼: {ModelType.GPT_4O_MINI.value}")
    print(f"  ç”¨é€”: é«˜æ•ˆçš„èŠå¤©å’Œåˆ†ææ¨¡å‹")

def demo_custom_model_config():
    """æ¼”ç¤ºè‡ªå®šä¹‰æ¨¡å‹é…ç½®"""
    print_separator("è‡ªå®šä¹‰æ¨¡å‹é…ç½®")
    
    # åˆ›å»ºè‡ªå®šä¹‰o4-minié…ç½®
    custom_config = ModelConfig(
        model_type=ModelType.GPT_4O_MINI,
        max_tokens=1500,
        temperature=0.2,
        top_p=0.9,
        frequency_penalty=0.1,
        presence_penalty=0.1,
        timeout=45.0
    )
    
    print("ğŸ› ï¸ è‡ªå®šä¹‰o4-minié…ç½®:")
    config_dict = custom_config.to_dict()
    for key, value in config_dict.items():
        print(f"  {key:18}: {value}")
    
    print("\nğŸ’¡ é…ç½®è¯´æ˜:")
    print("  â€¢ max_tokens: æ§åˆ¶è¾“å‡ºé•¿åº¦")
    print("  â€¢ temperature: æ§åˆ¶åˆ›é€ æ€§ (0.0-2.0)")
    print("  â€¢ top_p: æ ¸é‡‡æ ·å‚æ•° (0.0-1.0)")
    print("  â€¢ frequency_penalty: é¢‘ç‡æƒ©ç½š (-2.0-2.0)")
    print("  â€¢ presence_penalty: å­˜åœ¨æƒ©ç½š (-2.0-2.0)")
    print("  â€¢ timeout: APIè°ƒç”¨è¶…æ—¶æ—¶é—´")

def demo_cost_comparison():
    """æ¼”ç¤ºæˆæœ¬å¯¹æ¯”"""
    print_separator("æ¨¡å‹æˆæœ¬å¯¹æ¯”")
    
    # æ¨¡æ‹Ÿæˆæœ¬è®¡ç®— (å®é™…ä»·æ ¼å¯èƒ½æœ‰å˜åŒ–)
    models_cost = {
        "gpt-4o-mini": {"input": 0.00015, "output": 0.0006},  # æ¯1K tokens
        "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002},
        "gpt-4": {"input": 0.03, "output": 0.06},
        "gpt-4-32k": {"input": 0.06, "output": 0.12}
    }
    
    print("ğŸ’° æ¨¡å‹æˆæœ¬å¯¹æ¯” (æ¯1K tokens):")
    print(f"{'æ¨¡å‹':15} {'è¾“å…¥æˆæœ¬':>10} {'è¾“å‡ºæˆæœ¬':>10} {'æ€»æˆæœ¬(1K+1K)':>15}")
    print("-" * 55)
    
    for model, costs in models_cost.items():
        total_cost = costs["input"] + costs["output"]
        print(f"{model:15} ${costs['input']:>9.5f} ${costs['output']:>9.4f} ${total_cost:>14.5f}")
    
    print("\nğŸ“Š o4-miniçš„æˆæœ¬ä¼˜åŠ¿:")
    gpt4_cost = models_cost["gpt-4"]["input"] + models_cost["gpt-4"]["output"]
    o4mini_cost = models_cost["gpt-4o-mini"]["input"] + models_cost["gpt-4o-mini"]["output"]
    savings = ((gpt4_cost - o4mini_cost) / gpt4_cost) * 100
    print(f"  ç›¸æ¯”GPT-4èŠ‚çœæˆæœ¬: {savings:.1f}%")
    print(f"  æˆæœ¬æ¯”ä¾‹: 1:{gpt4_cost/o4mini_cost:.1f}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ NeuronOS o4-miniæ¨¡å‹é…ç½®æ¼”ç¤º")
    print("=" * 60)
    print("æœ¬æ¼”ç¤ºå±•ç¤ºäº†å¦‚ä½•é…ç½®å’Œä½¿ç”¨o4-miniæ¨¡å‹è¿›è¡Œå®‰å…¨åˆ†æ")
    
    demos = [
        ("o4-miniæ¨¡å‹é…ç½®", demo_o4_mini_configuration),
        ("æ¨¡å‹ç±»å‹æšä¸¾", demo_model_type_enum),
        ("è‡ªå®šä¹‰æ¨¡å‹é…ç½®", demo_custom_model_config),
        ("æ¨¡å‹æˆæœ¬å¯¹æ¯”", demo_cost_comparison)
    ]
    
    for name, demo_func in demos:
        try:
            demo_func()
            print(f"\nâœ… {name} æ¼”ç¤ºå®Œæˆ")
        except Exception as e:
            print(f"\nâŒ {name} æ¼”ç¤ºå¤±è´¥: {e}")
        
        input("\næŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€ä¸ªæ¼”ç¤º...")
    
    print_separator("æ¼”ç¤ºå®Œæˆ")
    print("ğŸ‰ o4-miniæ¨¡å‹å·²æˆåŠŸé…ç½®ä¸ºé¡¹ç›®çš„é»˜è®¤èŠå¤©æ¨¡å‹!")
    print("\nğŸ“ é…ç½®æ€»ç»“:")
    print("  â€¢ é»˜è®¤æ¨¡å‹: gpt-4o-mini")
    print("  â€¢ ç®€å•åˆ†æ: gpt-4o-mini")
    print("  â€¢ æ ‡å‡†åˆ†æ: gpt-4o-mini")
    print("  â€¢ è¯¦ç»†åˆ†æ: gpt-4")
    print("  â€¢ å…¨é¢åˆ†æ: gpt-4-32k")
    print("\nğŸ”— ç›¸å…³æ–‡ä»¶:")
    print("  â€¢ é…ç½®æ–‡ä»¶: /src/backend/config/openai_config.py")
    print("  â€¢ æœåŠ¡æ–‡ä»¶: /src/backend/services/openai_service.py")
    print("  â€¢ æµ‹è¯•æ–‡ä»¶: /tests/test_1_4_1_openai_integration.py")
    print("  â€¢ æ¼”ç¤ºæ–‡ä»¶: /examples/openai_integration_demo.py")

if __name__ == "__main__":
    main()