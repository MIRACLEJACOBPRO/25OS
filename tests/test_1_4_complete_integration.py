#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
1.4 AIåˆ†ææ¨¡å—å®Œæ•´é›†æˆæµ‹è¯•

æµ‹è¯• 1.4.1 OpenAI APIé›†æˆã€1.4.2 Pineconeå‘é‡æ•°æ®åº“ã€1.4.3 RAGæ£€ç´¢å¢å¼ºçš„å®Œæ•´å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
1. ä»1.3å¼‚å¸¸æ£€æµ‹è·å–å¼‚å¸¸äº‹ä»¶
2. å‘é‡åŒ–å¼‚å¸¸äº‹ä»¶
3. æ£€ç´¢ç›¸å…³çŸ¥è¯†
4. å¢å¼ºAIåˆ†æ
5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š

ä½œè€…: NeuronOS å¼€å‘å›¢é˜Ÿ
ç‰ˆæœ¬: 1.0.0
åˆ›å»ºæ—¶é—´: 2024-01-20
"""

import asyncio
import pytest
import os
import sys
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src', 'backend'))

from services.pinecone_service import (
    PineconeService, KnowledgeItem, KnowledgeType
)
from services.rag_service import (
    RAGService, RAGRequest, RAGMode, RetrievalStrategy
)
from services.openai_service import (
    OpenAIService, AnalysisRequest, AnalysisType, Priority
)
from services.knowledge_manager import KnowledgeManager
from services.local_filter_engine import LocalFilterEngine
from services.interfaces import AnomalyScore
from config.pinecone_config import get_config_manager


class TestCompleteIntegration:
    """å®Œæ•´é›†æˆæµ‹è¯•ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•"""
        self.config_manager = get_config_manager()
        
        # æœåŠ¡å®ä¾‹
        self.pinecone_service = None
        self.openai_service = None
        self.rag_service = None
        self.knowledge_manager = None
        self.filter_engine = None
        
        # æµ‹è¯•çŸ¥è¯†åº“
        self.knowledge_base = [
            {
                "title": "SQLæ³¨å…¥æ”»å‡»æ£€æµ‹ä¸é˜²æŠ¤",
                "content": "SQLæ³¨å…¥æ˜¯æœ€å¸¸è§çš„Webåº”ç”¨å®‰å…¨æ¼æ´ä¹‹ä¸€ã€‚æ”»å‡»è€…é€šè¿‡åœ¨è¾“å…¥å­—æ®µä¸­æ’å…¥æ¶æ„SQLä»£ç æ¥æ“æ§æ•°æ®åº“ã€‚æ£€æµ‹æ–¹æ³•åŒ…æ‹¬ï¼š1. ç›‘æ§å¼‚å¸¸çš„SQLæŸ¥è¯¢æ¨¡å¼ï¼Œç‰¹åˆ«æ˜¯åŒ…å«UNIONã€DROPã€INSERTç­‰å…³é”®å­—çš„æŸ¥è¯¢ 2. æ£€æŸ¥è¾“å…¥å‚æ•°ä¸­çš„SQLç‰¹æ®Šå­—ç¬¦å¦‚å•å¼•å·ã€åˆ†å·ã€æ³¨é‡Šç¬¦ 3. åˆ†ææ•°æ®åº“é”™è¯¯æ—¥å¿—ä¸­çš„å¼‚å¸¸æ¨¡å¼ 4. ä½¿ç”¨Webåº”ç”¨é˜²ç«å¢™(WAF)è¿›è¡Œå®æ—¶æ£€æµ‹ã€‚é˜²æŠ¤æªæ–½ï¼š1. ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢æˆ–é¢„ç¼–è¯‘è¯­å¥ 2. è¾“å…¥éªŒè¯å’Œè¿‡æ»¤ 3. æœ€å°æƒé™åŸåˆ™ 4. å®šæœŸå®‰å…¨å®¡è®¡",
                "knowledge_type": KnowledgeType.SECURITY_RULE,
                "tags": ["SQLæ³¨å…¥", "Webå®‰å…¨", "æ•°æ®åº“å®‰å…¨", "æ¼æ´æ£€æµ‹"],
                "source": "OWASPå®‰å…¨æŒ‡å—"
            },
            {
                "title": "æ¶æ„è¿›ç¨‹è¡Œä¸ºåˆ†æä¸æ£€æµ‹",
                "content": "æ¶æ„è¿›ç¨‹é€šå¸¸è¡¨ç°å‡ºå¼‚å¸¸çš„è¡Œä¸ºæ¨¡å¼ï¼Œå¯é€šè¿‡ä»¥ä¸‹æŒ‡æ ‡è¿›è¡Œæ£€æµ‹ï¼š1. è¿›ç¨‹åˆ›å»ºæ¨¡å¼å¼‚å¸¸ï¼šé¢‘ç¹åˆ›å»ºå­è¿›ç¨‹ã€åˆ›å»ºéšè—è¿›ç¨‹ã€è¿›ç¨‹åç§°ä¼ªè£… 2. æ–‡ä»¶ç³»ç»Ÿæ“ä½œå¼‚å¸¸ï¼šè®¿é—®æ•æ„Ÿæ–‡ä»¶ã€ä¿®æ”¹ç³»ç»Ÿæ–‡ä»¶ã€åˆ›å»ºå¯æ‰§è¡Œæ–‡ä»¶ 3. ç½‘ç»œè¡Œä¸ºå¼‚å¸¸ï¼šè¿æ¥å¯ç–‘IPã€å¤§é‡æ•°æ®ä¼ è¾“ã€ä½¿ç”¨éæ ‡å‡†ç«¯å£ 4. æƒé™æå‡è¡Œä¸ºï¼šå°è¯•è·å–ç®¡ç†å‘˜æƒé™ã€ä¿®æ”¹ç³»ç»Ÿé…ç½® 5. æŒä¹…åŒ–è¡Œä¸ºï¼šä¿®æ”¹å¯åŠ¨é¡¹ã€åˆ›å»ºè®¡åˆ’ä»»åŠ¡ã€å®‰è£…æœåŠ¡ã€‚æ£€æµ‹æŠ€æœ¯åŒ…æ‹¬è¡Œä¸ºåˆ†æã€æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹ã€ç­¾ååŒ¹é…ç­‰",
                "knowledge_type": KnowledgeType.THREAT_INTELLIGENCE,
                "tags": ["æ¶æ„è¿›ç¨‹", "è¡Œä¸ºåˆ†æ", "å¨èƒæ£€æµ‹", "ç³»ç»Ÿå®‰å…¨"],
                "source": "å¨èƒæƒ…æŠ¥æ•°æ®åº“"
            },
            {
                "title": "ç½‘ç»œæµé‡å¼‚å¸¸æ£€æµ‹æ–¹æ³•",
                "content": "ç½‘ç»œæµé‡å¼‚å¸¸å¯èƒ½æŒ‡ç¤ºå¤šç§å®‰å…¨å¨èƒï¼ŒåŒ…æ‹¬DDoSæ”»å‡»ã€æ•°æ®æ³„éœ²ã€æ¶æ„é€šä¿¡ç­‰ã€‚æ£€æµ‹æ–¹æ³•ï¼š1. åŸºçº¿å»ºç«‹ï¼šæ”¶é›†æ­£å¸¸æµé‡æ¨¡å¼ï¼Œå»ºç«‹æµé‡åŸºçº¿ 2. ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹ï¼šç›‘æ§æµé‡é‡ã€è¿æ¥æ•°ã€åè®®åˆ†å¸ƒçš„å¼‚å¸¸å˜åŒ– 3. æ¨¡å¼è¯†åˆ«ï¼šè¯†åˆ«å·²çŸ¥æ”»å‡»æ¨¡å¼ï¼Œå¦‚DDoSç‰¹å¾ã€åƒµå°¸ç½‘ç»œé€šä¿¡æ¨¡å¼ 4. åœ°ç†ä½ç½®åˆ†æï¼šæ£€æµ‹æ¥è‡ªå¼‚å¸¸åœ°ç†ä½ç½®çš„è¿æ¥ 5. æ—¶é—´æ¨¡å¼åˆ†æï¼šè¯†åˆ«éæ­£å¸¸æ—¶é—´çš„å¼‚å¸¸æ´»åŠ¨ã€‚æŠ€æœ¯æ‰‹æ®µåŒ…æ‹¬æ·±åº¦åŒ…æ£€æµ‹(DPI)ã€æœºå™¨å­¦ä¹ ç®—æ³•ã€è¡Œä¸ºåˆ†æç­‰",
                "knowledge_type": KnowledgeType.ANALYSIS_TEMPLATE,
                "tags": ["ç½‘ç»œå®‰å…¨", "æµé‡åˆ†æ", "å¼‚å¸¸æ£€æµ‹", "DDoSé˜²æŠ¤"],
                "source": "ç½‘ç»œå®‰å…¨åˆ†ææ‰‹å†Œ"
            },
            {
                "title": "XSSè·¨ç«™è„šæœ¬æ”»å‡»é˜²æŠ¤ç­–ç•¥",
                "content": "è·¨ç«™è„šæœ¬æ”»å‡»(XSS)æ˜¯Webåº”ç”¨ä¸­çš„å¸¸è§æ¼æ´ï¼Œæ”»å‡»è€…é€šè¿‡æ³¨å…¥æ¶æ„è„šæœ¬æ¥çªƒå–ç”¨æˆ·ä¿¡æ¯æˆ–åŠ«æŒä¼šè¯ã€‚é˜²æŠ¤ç­–ç•¥ï¼š1. è¾“å…¥éªŒè¯ï¼šå¯¹æ‰€æœ‰ç”¨æˆ·è¾“å…¥è¿›è¡Œä¸¥æ ¼éªŒè¯å’Œè¿‡æ»¤ 2. è¾“å‡ºç¼–ç ï¼šå¯¹è¾“å‡ºåˆ°HTMLé¡µé¢çš„å†…å®¹è¿›è¡Œé€‚å½“ç¼–ç  3. å†…å®¹å®‰å…¨ç­–ç•¥(CSP)ï¼šè®¾ç½®CSPå¤´éƒ¨é™åˆ¶è„šæœ¬æ‰§è¡Œ 4. HttpOnly Cookieï¼šé˜²æ­¢JavaScriptè®¿é—®æ•æ„ŸCookie 5. å®‰å…¨æ¡†æ¶ï¼šä½¿ç”¨å…·æœ‰å†…ç½®XSSé˜²æŠ¤çš„å¼€å‘æ¡†æ¶ã€‚æ£€æµ‹æ–¹æ³•åŒ…æ‹¬é™æ€ä»£ç åˆ†æã€åŠ¨æ€æ‰«æã€æ¸—é€æµ‹è¯•ç­‰",
                "knowledge_type": KnowledgeType.SECURITY_RULE,
                "tags": ["XSS", "Webå®‰å…¨", "è„šæœ¬æ³¨å…¥", "å‰ç«¯å®‰å…¨"],
                "source": "Webå®‰å…¨æœ€ä½³å®è·µ"
            },
            {
                "title": "APTé«˜çº§æŒç»­å¨èƒæ£€æµ‹",
                "content": "é«˜çº§æŒç»­å¨èƒ(APT)æ˜¯å¤æ‚çš„ã€é•¿æœŸçš„ç½‘ç»œæ”»å‡»ï¼Œé€šå¸¸ç”±å›½å®¶çº§æˆ–æœ‰ç»„ç»‡çš„æ”»å‡»è€…å‘èµ·ã€‚ç‰¹å¾åŒ…æ‹¬ï¼š1. å¤šé˜¶æ®µæ”»å‡»ï¼šä¾¦å¯Ÿã€åˆå§‹å…¥ä¾µã€æ¨ªå‘ç§»åŠ¨ã€æ•°æ®æ”¶é›†ã€æ•°æ®å¤–æ³„ 2. éšè”½æ€§å¼ºï¼šä½¿ç”¨åˆæ³•å·¥å…·ã€åŠ å¯†é€šä¿¡ã€å®šæ—¶æ´»åŠ¨ 3. ç›®æ ‡æ˜ç¡®ï¼šé’ˆå¯¹ç‰¹å®šç»„ç»‡æˆ–ä¸ªäººçš„æœ‰ä»·å€¼ä¿¡æ¯ã€‚æ£€æµ‹æ–¹æ³•ï¼š1. è¡Œä¸ºåˆ†æï¼šç›‘æ§å¼‚å¸¸çš„ç”¨æˆ·å’Œç³»ç»Ÿè¡Œä¸º 2. å¨èƒç‹©çŒï¼šä¸»åŠ¨æœç´¢å¨èƒæŒ‡æ ‡ 3. å…³è”åˆ†æï¼šå…³è”å¤šä¸ªå®‰å…¨äº‹ä»¶å‘ç°æ”»å‡»é“¾ 4. å¨èƒæƒ…æŠ¥ï¼šåˆ©ç”¨å¤–éƒ¨å¨èƒæƒ…æŠ¥è¿›è¡ŒåŒ¹é…",
                "knowledge_type": KnowledgeType.THREAT_INTELLIGENCE,
                "tags": ["APT", "é«˜çº§å¨èƒ", "å¨èƒç‹©çŒ", "è¡Œä¸ºåˆ†æ"],
                "source": "é«˜çº§å¨èƒç ”ç©¶æŠ¥å‘Š"
            }
        ]
        
        # æ¨¡æ‹Ÿå¼‚å¸¸äº‹ä»¶
        self.test_anomaly_events = [
            {
                "event_id": "evt_001",
                "event_type": "web_attack",
                "description": "æ£€æµ‹åˆ°æ¥è‡ªIP 192.168.1.100çš„SQLæ³¨å…¥æ”»å‡»å°è¯•ï¼Œç›®æ ‡URL /login.phpï¼ŒpayloadåŒ…å«'OR 1=1--",
                "severity": "high",
                "source_ip": "192.168.1.100",
                "target_url": "/login.php",
                "payload": "admin' OR '1'='1' --",
                "timestamp": datetime.now().isoformat(),
                "anomaly_score": AnomalyScore(
                    total_score=0.92,
                    category_scores={"web_security": 0.95, "injection": 0.9},
                    risk_level="high",
                    indicators=["sql_injection_pattern", "malicious_payload", "authentication_bypass"],
                    confidence=0.93,
                    explanation="æ˜ç¡®çš„SQLæ³¨å…¥æ”»å‡»æ¨¡å¼ï¼Œå°è¯•ç»•è¿‡èº«ä»½éªŒè¯"
                )
            },
            {
                "event_id": "evt_002",
                "event_type": "process_anomaly",
                "description": "æ£€æµ‹åˆ°å¯ç–‘è¿›ç¨‹/tmp/update.exeæ‰§è¡Œå¼‚å¸¸è¡Œä¸ºï¼Œå°è¯•è®¿é—®/etc/passwdå’Œ/etc/shadowæ–‡ä»¶ï¼Œå¹¶å»ºç«‹åˆ°å¤–éƒ¨IP 203.0.113.50çš„ç½‘ç»œè¿æ¥",
                "severity": "critical",
                "process_name": "update.exe",
                "process_path": "/tmp/update.exe",
                "accessed_files": ["/etc/passwd", "/etc/shadow"],
                "network_connections": ["203.0.113.50:443"],
                "timestamp": datetime.now().isoformat(),
                "anomaly_score": AnomalyScore(
                    total_score=0.96,
                    category_scores={"process": 0.98, "file_access": 0.95, "network": 0.94},
                    risk_level="critical",
                    indicators=["suspicious_executable", "sensitive_file_access", "external_communication", "privilege_escalation"],
                    confidence=0.97,
                    explanation="é«˜åº¦å¯ç–‘çš„æ¶æ„è¿›ç¨‹è¡Œä¸ºï¼Œå¯èƒ½æ˜¯APTæ”»å‡»çš„ä¸€éƒ¨åˆ†"
                )
            },
            {
                "event_id": "evt_003",
                "event_type": "network_anomaly",
                "description": "æ£€æµ‹åˆ°å¼‚å¸¸ç½‘ç»œæµé‡æ¨¡å¼ï¼Œæ¥è‡ªå†…ç½‘ä¸»æœº192.168.1.50å‘å¤–éƒ¨IP 198.51.100.25ä¼ è¾“å¤§é‡æ•°æ®(500MB)ï¼Œä½¿ç”¨éæ ‡å‡†ç«¯å£8443",
                "severity": "medium",
                "source_ip": "192.168.1.50",
                "dest_ip": "198.51.100.25",
                "dest_port": 8443,
                "bytes_transferred": 524288000,
                "duration": 3600,
                "timestamp": datetime.now().isoformat(),
                "anomaly_score": AnomalyScore(
                    total_score=0.78,
                    category_scores={"network": 0.8, "data_transfer": 0.85, "timing": 0.7},
                    risk_level="medium",
                    indicators=["large_data_transfer", "unusual_port", "external_destination", "off_hours_activity"],
                    confidence=0.82,
                    explanation="å¯èƒ½çš„æ•°æ®æ³„éœ²è¡Œä¸ºï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥"
                )
            }
        ]
    
    async def setup_services(self) -> bool:
        """è®¾ç½®æ‰€æœ‰æµ‹è¯•æœåŠ¡
        
        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        try:
            print("\n=== è®¾ç½®å®Œæ•´é›†æˆæµ‹è¯•æœåŠ¡ ===")
            
            # è·å–é…ç½®
            pinecone_config = self.config_manager.get_pinecone_config()
            
            # åˆå§‹åŒ– Pinecone æœåŠ¡
            self.pinecone_service = PineconeService(
                api_key=pinecone_config.api_key,
                environment=pinecone_config.environment,
                index_name=pinecone_config.index_name,
                openai_api_key=os.getenv("OPENAI_API_KEY")
            )
            
            # åˆå§‹åŒ– OpenAI æœåŠ¡
            self.openai_service = OpenAIService(
                api_key=os.getenv("OPENAI_API_KEY")
            )
            
            # åˆå§‹åŒ– RAG æœåŠ¡
            self.rag_service = RAGService(
                pinecone_service=self.pinecone_service,
                openai_service=self.openai_service
            )
            
            # åˆå§‹åŒ–çŸ¥è¯†ç®¡ç†æœåŠ¡
            self.knowledge_manager = KnowledgeManager(
                pinecone_service=self.pinecone_service
            )
            
            # åˆå§‹åŒ–è¿‡æ»¤å¼•æ“ï¼ˆæ¨¡æ‹Ÿ1.3å¼‚å¸¸æ£€æµ‹ï¼‰
            self.filter_engine = LocalFilterEngine()
            
            # åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡
            services = [
                ("Pinecone", self.pinecone_service),
                ("OpenAI", self.openai_service),
                ("RAG", self.rag_service),
                ("FilterEngine", self.filter_engine)
            ]
            
            for service_name, service in services:
                if hasattr(service, 'initialize'):
                    success = await service.initialize()
                    if not success:
                        print(f"âŒ {service_name} æœåŠ¡åˆå§‹åŒ–å¤±è´¥")
                        return False
                    print(f"âœ… {service_name} æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
            print("âœ… æ‰€æœ‰æœåŠ¡è®¾ç½®å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æœåŠ¡è®¾ç½®å¤±è´¥: {e}")
            return False
    
    async def setup_knowledge_base(self) -> bool:
        """è®¾ç½®çŸ¥è¯†åº“
        
        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        try:
            print("\n=== è®¾ç½®çŸ¥è¯†åº“ ===")
            
            upload_count = 0
            
            for i, kb_item in enumerate(self.knowledge_base):
                print(f"ä¸Šä¼ çŸ¥è¯† {i+1}: {kb_item['title']}")
                
                # åˆ›å»ºçŸ¥è¯†é¡¹
                knowledge_item = KnowledgeItem(
                    id=f"kb_{i+1:03d}",
                    title=kb_item["title"],
                    content=kb_item["content"],
                    knowledge_type=kb_item["knowledge_type"],
                    tags=kb_item["tags"],
                    source=kb_item["source"]
                )
                
                # ä¸Šä¼ çŸ¥è¯†
                success = await self.pinecone_service.upload_knowledge(knowledge_item)
                if success:
                    upload_count += 1
                    print(f"  âœ… ä¸Šä¼ æˆåŠŸ")
                else:
                    print(f"  âŒ ä¸Šä¼ å¤±è´¥")
                
                await asyncio.sleep(0.5)
            
            print(f"\nğŸ“Š çŸ¥è¯†åº“è®¾ç½®å®Œæˆ: {upload_count}/{len(self.knowledge_base)} æˆåŠŸ")
            return upload_count >= len(self.knowledge_base) * 0.8  # 80% æˆåŠŸç‡
            
        except Exception as e:
            print(f"âŒ çŸ¥è¯†åº“è®¾ç½®å¤±è´¥: {e}")
            return False
    
    async def test_end_to_end_workflow(self) -> bool:
        """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹
        
        Returns:
            æ˜¯å¦æµ‹è¯•æˆåŠŸ
        """
        try:
            print("\n=== æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹ ===")
            
            workflow_results = []
            
            for i, event in enumerate(self.test_anomaly_events):
                print(f"\nå¤„ç†å¼‚å¸¸äº‹ä»¶ {i+1}: {event['event_type']}")
                print(f"äº‹ä»¶æè¿°: {event['description'][:100]}...")
                
                # æ­¥éª¤1: æ¨¡æ‹Ÿ1.3å¼‚å¸¸æ£€æµ‹è¾“å‡º
                print("\næ­¥éª¤1: å¼‚å¸¸æ£€æµ‹å¤„ç†")
                filter_result = await self.simulate_anomaly_detection(event)
                if not filter_result:
                    print("âŒ å¼‚å¸¸æ£€æµ‹å¤±è´¥")
                    workflow_results.append(False)
                    continue
                print("âœ… å¼‚å¸¸æ£€æµ‹å®Œæˆ")
                
                # æ­¥éª¤2: å¼‚å¸¸äº‹ä»¶å‘é‡åŒ–
                print("\næ­¥éª¤2: å¼‚å¸¸äº‹ä»¶å‘é‡åŒ–")
                vector_result = await self.rag_service.vectorize_anomaly_event(event)
                if not vector_result:
                    print("âŒ å‘é‡åŒ–å¤±è´¥")
                    workflow_results.append(False)
                    continue
                print("âœ… å‘é‡åŒ–æˆåŠŸ")
                
                # æ­¥éª¤3: æ£€ç´¢ç›¸å…³çŸ¥è¯†
                print("\næ­¥éª¤3: æ£€ç´¢ç›¸å…³çŸ¥è¯†")
                knowledge_items = await self.rag_service.retrieve_relevant_knowledge(
                    query_text=event["description"],
                    event_type=event["event_type"],
                    max_items=3
                )
                if not knowledge_items:
                    print("âŒ çŸ¥è¯†æ£€ç´¢å¤±è´¥")
                    workflow_results.append(False)
                    continue
                print(f"âœ… æ£€ç´¢åˆ° {len(knowledge_items)} ä¸ªç›¸å…³çŸ¥è¯†")
                
                # æ­¥éª¤4: æ‰§è¡Œå¢å¼ºåˆ†æ
                print("\næ­¥éª¤4: æ‰§è¡Œå¢å¼ºåˆ†æ")
                rag_request = RAGRequest(
                    anomaly_event=event,
                    analysis_type=AnalysisType.COMPREHENSIVE_ANALYSIS,
                    mode=RAGMode.ENHANCED,
                    strategy=RetrievalStrategy.HYBRID,
                    max_knowledge_items=3
                )
                
                rag_response = await self.rag_service.enhance_analysis(rag_request)
                if not rag_response or not rag_response.enhanced_analysis:
                    print("âŒ å¢å¼ºåˆ†æå¤±è´¥")
                    workflow_results.append(False)
                    continue
                print("âœ… å¢å¼ºåˆ†ææˆåŠŸ")
                
                # æ­¥éª¤5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š
                print("\næ­¥éª¤5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š")
                report = await self.generate_comprehensive_report(
                    event, rag_response, knowledge_items
                )
                if not report:
                    print("âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
                    workflow_results.append(False)
                    continue
                print("âœ… ç»¼åˆæŠ¥å‘Šç”ŸæˆæˆåŠŸ")
                
                # æ˜¾ç¤ºå¤„ç†ç»“æœ
                self.display_workflow_result(event, rag_response, report)
                
                workflow_results.append(True)
                await asyncio.sleep(1)
            
            success_count = sum(workflow_results)
            total_count = len(workflow_results)
            
            print(f"\nğŸ“Š ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹ç»“æœ: {success_count}/{total_count} æˆåŠŸ")
            
            return success_count >= total_count * 0.8  # 80% æˆåŠŸç‡
            
        except Exception as e:
            print(f"âŒ ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def simulate_anomaly_detection(self, event: Dict[str, Any]) -> bool:
        """æ¨¡æ‹Ÿ1.3å¼‚å¸¸æ£€æµ‹å¤„ç†
        
        Args:
            event: å¼‚å¸¸äº‹ä»¶
            
        Returns:
            æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        try:
            # æ¨¡æ‹Ÿè¿‡æ»¤å¼•æ“å¤„ç†
            # åœ¨å®é™…ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨ LocalFilterEngine çš„å¤„ç†æ–¹æ³•
            print(f"  æ£€æµ‹åˆ°å¼‚å¸¸: {event['event_type']}")
            print(f"  é£é™©ç­‰çº§: {event['anomaly_score'].risk_level}")
            print(f"  ç½®ä¿¡åº¦: {event['anomaly_score'].confidence:.3f}")
            return True
        except Exception as e:
            print(f"å¼‚å¸¸æ£€æµ‹æ¨¡æ‹Ÿå¤±è´¥: {e}")
            return False
    
    async def generate_comprehensive_report(
        self, 
        event: Dict[str, Any], 
        rag_response: Any, 
        knowledge_items: List[Any]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        
        Args:
            event: å¼‚å¸¸äº‹ä»¶
            rag_response: RAGå“åº”
            knowledge_items: ç›¸å…³çŸ¥è¯†é¡¹
            
        Returns:
            ç»¼åˆæŠ¥å‘Š
        """
        try:
            report = {
                "event_summary": {
                    "event_id": event["event_id"],
                    "event_type": event["event_type"],
                    "severity": event["severity"],
                    "timestamp": event["timestamp"],
                    "risk_score": event["anomaly_score"].total_score
                },
                "analysis_results": {
                    "original_analysis": {
                        "summary": rag_response.original_analysis.summary,
                        "risk_score": rag_response.original_analysis.risk_score,
                        "confidence": rag_response.original_analysis.confidence
                    },
                    "enhanced_analysis": {
                        "summary": rag_response.enhanced_analysis.summary,
                        "risk_score": rag_response.enhanced_analysis.risk_score,
                        "confidence": rag_response.enhanced_analysis.confidence,
                        "recommendations": rag_response.enhanced_analysis.recommendations
                    },
                    "improvement_metrics": {
                        "confidence_improvement": rag_response.enhanced_analysis.confidence - rag_response.original_analysis.confidence,
                        "knowledge_relevance": rag_response.knowledge_relevance_score,
                        "knowledge_count": len(knowledge_items)
                    }
                },
                "knowledge_context": [
                    {
                        "title": item.knowledge_item.title,
                        "relevance_score": item.score,
                        "knowledge_type": item.knowledge_item.knowledge_type.value,
                        "tags": item.knowledge_item.tags
                    }
                    for item in knowledge_items
                ],
                "recommendations": rag_response.enhanced_analysis.recommendations,
                "next_actions": self.generate_next_actions(event, rag_response)
            }
            
            return report
            
        except Exception as e:
            print(f"ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def generate_next_actions(self, event: Dict[str, Any], rag_response: Any) -> List[str]:
        """ç”Ÿæˆåç»­è¡ŒåŠ¨å»ºè®®
        
        Args:
            event: å¼‚å¸¸äº‹ä»¶
            rag_response: RAGå“åº”
            
        Returns:
            è¡ŒåŠ¨å»ºè®®åˆ—è¡¨
        """
        actions = []
        
        # åŸºäºé£é™©ç­‰çº§ç”Ÿæˆè¡ŒåŠ¨å»ºè®®
        risk_level = event["anomaly_score"].risk_level
        
        if risk_level == "critical":
            actions.extend([
                "ç«‹å³éš”ç¦»å—å½±å“çš„ç³»ç»Ÿ",
                "å¯åŠ¨åº”æ€¥å“åº”æµç¨‹",
                "é€šçŸ¥å®‰å…¨å›¢é˜Ÿå’Œç®¡ç†å±‚",
                "æ”¶é›†å’Œä¿å­˜ç›¸å…³è¯æ®"
            ])
        elif risk_level == "high":
            actions.extend([
                "åŠ å¼ºç›‘æ§ç›¸å…³ç³»ç»Ÿ",
                "å®æ–½ä¸´æ—¶é˜²æŠ¤æªæ–½",
                "è¿›è¡Œæ·±å…¥è°ƒæŸ¥åˆ†æ",
                "æ›´æ–°å®‰å…¨ç­–ç•¥"
            ])
        else:
            actions.extend([
                "æŒç»­ç›‘æ§äº‹ä»¶å‘å±•",
                "è®°å½•äº‹ä»¶è¯¦æƒ…",
                "è¯„ä¼°æ½œåœ¨å½±å“",
                "è€ƒè™‘é¢„é˜²æ€§æªæ–½"
            ])
        
        return actions
    
    def display_workflow_result(
        self, 
        event: Dict[str, Any], 
        rag_response: Any, 
        report: Dict[str, Any]
    ) -> None:
        """æ˜¾ç¤ºå·¥ä½œæµç¨‹ç»“æœ
        
        Args:
            event: å¼‚å¸¸äº‹ä»¶
            rag_response: RAGå“åº”
            report: ç»¼åˆæŠ¥å‘Š
        """
        print(f"\nğŸ“‹ å¤„ç†ç»“æœæ‘˜è¦:")
        print(f"  äº‹ä»¶ID: {event['event_id']}")
        print(f"  äº‹ä»¶ç±»å‹: {event['event_type']}")
        print(f"  åŸå§‹é£é™©è¯„åˆ†: {rag_response.original_analysis.risk_score:.2f}")
        print(f"  å¢å¼ºé£é™©è¯„åˆ†: {rag_response.enhanced_analysis.risk_score:.2f}")
        print(f"  ç½®ä¿¡åº¦æå‡: {report['analysis_results']['improvement_metrics']['confidence_improvement']:.3f}")
        print(f"  ä½¿ç”¨çŸ¥è¯†æ•°: {len(rag_response.retrieved_knowledge)}")
        print(f"  ç”Ÿæˆå»ºè®®æ•°: {len(rag_response.enhanced_analysis.recommendations)}")
    
    async def test_performance_metrics(self) -> bool:
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡
        
        Returns:
            æ˜¯å¦æµ‹è¯•æˆåŠŸ
        """
        try:
            print("\n=== æµ‹è¯•æ€§èƒ½æŒ‡æ ‡ ===")
            
            # è·å–å„æœåŠ¡ç»Ÿè®¡ä¿¡æ¯
            services_stats = {}
            
            # Pinecone æœåŠ¡ç»Ÿè®¡
            pinecone_stats = await self.pinecone_service.get_stats()
            services_stats['pinecone'] = pinecone_stats
            
            # RAG æœåŠ¡ç»Ÿè®¡
            rag_stats = await self.rag_service.get_stats()
            services_stats['rag'] = rag_stats
            
            # çŸ¥è¯†ç®¡ç†ç»Ÿè®¡
            km_stats = await self.knowledge_manager.get_stats()
            services_stats['knowledge_manager'] = km_stats
            
            # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
            print(f"\nğŸ“Š æ€§èƒ½æŒ‡æ ‡æ±‡æ€»:")
            
            print(f"\nğŸ” Pinecone æœåŠ¡:")
            print(f"  æ€»åµŒå…¥æ•°: {pinecone_stats.get('total_embeddings', 0)}")
            print(f"  æ€»æœç´¢æ•°: {pinecone_stats.get('total_searches', 0)}")
            print(f"  ç¼“å­˜å‘½ä¸­ç‡: {pinecone_stats.get('cache_hits', 0) / max(pinecone_stats.get('total_embeddings', 1), 1) * 100:.1f}%")
            print(f"  å¹³å‡æœç´¢æ—¶é—´: {pinecone_stats.get('search_time', 0):.3f}s")
            
            print(f"\nğŸ¤– RAG æœåŠ¡:")
            print(f"  æ€»å¢å¼ºè¯·æ±‚: {rag_stats.get('total_enhancements', 0)}")
            print(f"  æˆåŠŸå¢å¼º: {rag_stats.get('successful_enhancements', 0)}")
            print(f"  å¹³å‡å¢å¼ºæ—¶é—´: {rag_stats.get('average_enhancement_time', 0):.3f}s")
            
            print(f"\nğŸ“š çŸ¥è¯†ç®¡ç†:")
            print(f"  æ€»å¯¼å…¥æ•°: {km_stats.get('total_imports', 0)}")
            print(f"  æˆåŠŸç‡: {km_stats.get('successful_imports', 0) / max(km_stats.get('total_imports', 1), 1) * 100:.1f}%")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ€§èƒ½æŒ‡æ ‡æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def cleanup_services(self) -> None:
        """æ¸…ç†æµ‹è¯•æœåŠ¡"""
        try:
            print("\n=== æ¸…ç†æµ‹è¯•æœåŠ¡ ===")
            
            services = [
                ("RAG", self.rag_service),
                ("Pinecone", self.pinecone_service),
                ("OpenAI", self.openai_service)
            ]
            
            for service_name, service in services:
                if service and hasattr(service, 'close'):
                    await service.close()
                    print(f"âœ… {service_name} æœåŠ¡å·²å…³é—­")
            
            print("âœ… æœåŠ¡æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æœåŠ¡æ¸…ç†å¤±è´¥: {e}")
    
    async def run_complete_integration_test(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•
        
        Returns:
            æµ‹è¯•ç»“æœå­—å…¸
        """
        print("\n" + "="*70)
        print("ğŸš€ å¼€å§‹ 1.4 AIåˆ†ææ¨¡å—å®Œæ•´é›†æˆæµ‹è¯•")
        print("="*70)
        
        start_time = datetime.now()
        test_results = {
            'start_time': start_time.isoformat(),
            'tests': {},
            'overall_success': False,
            'error_message': None
        }
        
        try:
            # 1. è®¾ç½®æœåŠ¡
            setup_success = await self.setup_services()
            test_results['tests']['setup_services'] = setup_success
            
            if not setup_success:
                test_results['error_message'] = "æœåŠ¡è®¾ç½®å¤±è´¥"
                return test_results
            
            # 2. è®¾ç½®çŸ¥è¯†åº“
            kb_success = await self.setup_knowledge_base()
            test_results['tests']['setup_knowledge_base'] = kb_success
            
            # 3. æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹
            workflow_success = await self.test_end_to_end_workflow()
            test_results['tests']['end_to_end_workflow'] = workflow_success
            
            # 4. æµ‹è¯•æ€§èƒ½æŒ‡æ ‡
            performance_success = await self.test_performance_metrics()
            test_results['tests']['performance_metrics'] = performance_success
            
            # è®¡ç®—æ€»ä½“æˆåŠŸç‡
            total_tests = len(test_results['tests'])
            successful_tests = sum(test_results['tests'].values())
            success_rate = successful_tests / total_tests
            
            test_results['overall_success'] = success_rate >= 0.8  # 80% æˆåŠŸç‡
            test_results['success_rate'] = success_rate
            test_results['successful_tests'] = successful_tests
            test_results['total_tests'] = total_tests
            
        except Exception as e:
            test_results['error_message'] = str(e)
            print(f"âŒ é›†æˆæµ‹è¯•å¼‚å¸¸: {e}")
        
        finally:
            # æ¸…ç†æœåŠ¡
            await self.cleanup_services()
            
            end_time = datetime.now()
            test_results['end_time'] = end_time.isoformat()
            test_results['duration'] = (end_time - start_time).total_seconds()
        
        return test_results
    
    def print_test_summary(self, results: Dict[str, Any]) -> None:
        """æ‰“å°æµ‹è¯•æ‘˜è¦
        
        Args:
            results: æµ‹è¯•ç»“æœ
        """
        print("\n" + "="*70)
        print("ğŸ“‹ 1.4 AIåˆ†ææ¨¡å—å®Œæ•´é›†æˆæµ‹è¯•æ‘˜è¦")
        print("="*70)
        
        print(f"\nâ±ï¸  æµ‹è¯•æ—¶é—´: {results.get('duration', 0):.2f} ç§’")
        print(f"ğŸ“Š æˆåŠŸç‡: {results.get('success_rate', 0)*100:.1f}% ({results.get('successful_tests', 0)}/{results.get('total_tests', 0)})")
        
        print("\nğŸ§ª è¯¦ç»†æµ‹è¯•ç»“æœ:")
        for test_name, success in results.get('tests', {}).items():
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            print(f"  {test_name}: {status}")
        
        if results.get('overall_success'):
            print("\nğŸ‰ 1.4 AIåˆ†ææ¨¡å—å®Œæ•´é›†æˆæµ‹è¯•æˆåŠŸï¼")
            print("âœ… 1.4.1 OpenAI APIé›†æˆåŠŸèƒ½æ­£å¸¸")
            print("âœ… 1.4.2 Pineconeå‘é‡æ•°æ®åº“é›†æˆåŠŸèƒ½æ­£å¸¸")
            print("âœ… 1.4.3 RAGæ£€ç´¢å¢å¼ºç”ŸæˆåŠŸèƒ½æ­£å¸¸")
            print("âœ… ä»å¼‚å¸¸æ£€æµ‹åˆ°AIåˆ†æçš„å®Œæ•´å·¥ä½œæµç¨‹éªŒè¯é€šè¿‡")
            print("âœ… çŸ¥è¯†åº“å¢å¼ºAIåˆ†ææ•ˆæœæ˜¾è‘—")
        else:
            print("\nâš ï¸  1.4 AIåˆ†ææ¨¡å—é›†æˆæµ‹è¯•å­˜åœ¨é—®é¢˜")
            if results.get('error_message'):
                print(f"âŒ é”™è¯¯ä¿¡æ¯: {results['error_message']}")
        
        print("\n" + "="*70)


async def test_complete_integration_flow():
    """æµ‹è¯•å®Œæ•´é›†æˆæµç¨‹"""
    tester = TestCompleteIntegration()
    results = await tester.run_complete_integration_test()
    tester.print_test_summary(results)
    return results


if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´é›†æˆæµ‹è¯•
    try:
        results = asyncio.run(test_complete_integration_flow())
        
        # æ ¹æ®æµ‹è¯•ç»“æœè®¾ç½®é€€å‡ºç 
        exit_code = 0 if results.get('overall_success') else 1
        sys.exit(exit_code)
        
    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)