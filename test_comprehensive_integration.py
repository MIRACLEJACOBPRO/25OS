#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»¼åˆé›†æˆæµ‹è¯•è„šæœ¬
ç”¨äºå…¨é¢éªŒè¯1.1è‡³1.3æ¨¡å—çš„åŠŸèƒ½å®Œæ•´æ€§å’Œåä½œèƒ½åŠ›

æµ‹è¯•èŒƒå›´:
- 1.1 åŸºç¡€è®¾æ–½æ¨¡å—
- 1.2 æ—¥å¿—è§£ææ¨¡å— (åŒ…å«å­æ¨¡å— 1.2.1, 1.2.2, 1.2.3)
- 1.3 å¼‚å¸¸æ£€æµ‹ä¸è¿‡æ»¤æ¨¡å— (åŒ…å«å­æ¨¡å— 1.3.1, 1.3.2)
"""

import os
import sys
import asyncio
import tempfile
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/home/xzj/01_Project/B_25OS/src/backend')

# è®¾ç½®ç¯å¢ƒå˜é‡é¿å…ä¾èµ–é—®é¢˜
os.environ['OPENAI_API_KEY'] = 'test-key'
os.environ['PINECONE_API_KEY'] = 'test-key'
os.environ['PINECONE_ENVIRONMENT'] = 'test-env'


class ComprehensiveTestRunner:
    """ç»¼åˆæµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.test_results = {}
        self.total_tests = 0
        self.passed_tests = 0
        self.failed_tests = 0
        
    def log_test_result(self, module_name: str, success: bool, details: str = ""):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        self.test_results[module_name] = {
            'success': success,
            'details': details,
            'timestamp': datetime.now().isoformat()
        }
        self.total_tests += 1
        if success:
            self.passed_tests += 1
        else:
            self.failed_tests += 1
            
    async def test_1_1_infrastructure(self):
        """æµ‹è¯•1.1åŸºç¡€è®¾æ–½æ¨¡å—"""
        try:
            # æµ‹è¯•é…ç½®ç®¡ç†
            from config.filter_engine_config import FilterEngineConfig, create_default_config_file
            
            # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                config_path = f.name
                create_default_config_file(config_path)
            
            # æµ‹è¯•é…ç½®åŠ è½½
            config = FilterEngineConfig.from_file(config_path)
            assert config is not None
            assert hasattr(config, 'priority_filter_enabled')
            
            # æ¸…ç†
            os.unlink(config_path)
            
            self.log_test_result("1.1_infrastructure", True, "é…ç½®ç®¡ç†åŠŸèƒ½æ­£å¸¸")
            
        except Exception as e:
            import traceback
            error_msg = f"é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            self.log_test_result("1.1_infrastructure", False, error_msg)
    
    async def test_1_2_1_falco_log_parser(self):
        """æµ‹è¯•1.2.1 Falcoæ—¥å¿—è§£æå™¨"""
        try:
            from services.falco_log_parser import FalcoLogParser, StandardizedEvent
            
            # åˆ›å»ºä¸´æ—¶æ—¥å¿—æ–‡ä»¶
            with tempfile.NamedTemporaryFile(mode='w', suffix='.log', delete=False) as f:
                log_path = f.name
            
            parser = FalcoLogParser(log_path)
            
            # æµ‹è¯•æ—¥å¿—è§£æ
            test_log = {
                "time": "2024-01-01T10:00:00.000000000Z",
                "rule": "Terminal shell in container",
                "priority": "Notice",
                "output": "A shell was used as the entrypoint/exec point into a container",
                "output_fields": {
                    "container.id": "test123",
                    "proc.name": "bash",
                    "user.name": "root"
                }
            }
            
            event = parser.parse_event(json.dumps(test_log))
            assert isinstance(event, StandardizedEvent)
            assert event.rule_name == "Terminal shell in container"
            
            self.log_test_result("1.2.1_falco_log_parser", True, "æ—¥å¿—è§£æåŠŸèƒ½æ­£å¸¸")
            
        except Exception as e:
            self.log_test_result("1.2.1_falco_log_parser", False, f"é”™è¯¯: {str(e)}")
    
    async def test_1_2_2_graph_database(self):
        """æµ‹è¯•1.2.2å›¾æ•°æ®åº“ç®¡ç†"""
        try:
            from services.graph_database import GraphDatabaseManager, GraphNodeType
            
            # åˆ›å»ºç®¡ç†å™¨å®ä¾‹ï¼ˆä¸å®é™…è¿æ¥ï¼‰
            manager = GraphDatabaseManager(
                uri="bolt://localhost:7687",
                username="neo4j",
                password="password"
            )
            
            # æµ‹è¯•åŸºæœ¬å±æ€§
            assert manager.uri == "bolt://localhost:7687"
            assert manager.username == "neo4j"
            assert hasattr(manager, 'batch_size')
            
            # æµ‹è¯•èŠ‚ç‚¹ç±»å‹å¸¸é‡
            assert hasattr(GraphNodeType, 'EVENT')
            assert hasattr(GraphNodeType, 'PROCESS')
            
            self.log_test_result("1.2.2_graph_database", True, "å›¾æ•°æ®åº“ç®¡ç†å™¨åˆå§‹åŒ–æ­£å¸¸")
            
        except Exception as e:
            self.log_test_result("1.2.2_graph_database", False, f"é”™è¯¯: {str(e)}")
    
    async def test_1_2_3_log_volume_controller(self):
        """æµ‹è¯•1.2.3æ—¥å¿—é‡æ§åˆ¶å™¨"""
        try:
            from services.log_volume_controller import LogVolumeController, LogVolumeConfig
            
            # åˆ›å»ºé…ç½®
            config = LogVolumeConfig(
                max_file_size=100 * 1024 * 1024,  # 100MB
                max_files=10,
                enable_compression=True,
                base_sampling_rate=0.8
            )
            
            # åˆ›å»ºæ§åˆ¶å™¨
            controller = LogVolumeController(config)
            
            # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
            assert hasattr(controller, 'config')
            assert controller.config.max_file_size == 100 * 1024 * 1024
            
            # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯è·å–
            stats = controller.get_stats()
            assert isinstance(stats, dict)
            # æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯çš„åŸºæœ¬ç»“æ„
            assert isinstance(stats, dict)
            # LogVolumeControllerçš„statsåŒ…å«è¿™äº›å­—æ®µ
            expected_keys = ['total_events', 'sampled_events', 'dropped_events']
            assert any(key in stats for key in expected_keys)
            
            self.log_test_result("1.2.3_log_volume_controller", True, "æ—¥å¿—é‡æ§åˆ¶å™¨åŠŸèƒ½æ­£å¸¸")
            
        except Exception as e:
            import traceback
            error_msg = f"é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            self.log_test_result("1.2.3_log_volume_controller", False, error_msg)
    
    async def test_1_3_1_local_filter_engine(self):
        """æµ‹è¯•1.3.1æœ¬åœ°è¿‡æ»¤å¼•æ“"""
        try:
            from services.local_filter_engine import LocalFilterEngine
            from config.filter_engine_config import FilterEngineConfig
            
            # åˆ›å»ºé…ç½®
            config = FilterEngineConfig()
            
            # åˆ›å»ºå¼•æ“
            engine = LocalFilterEngine(config)
            
            # æµ‹è¯•åŸºæœ¬å±æ€§
            # æµ‹è¯•å¼•æ“çš„åŸºæœ¬å±æ€§
            assert engine is not None
            # LocalFilterEngineåº”è¯¥æœ‰è¿™äº›åŸºæœ¬æ–¹æ³•
            assert hasattr(engine, '__init__')
            
            self.log_test_result("1.3.1_local_filter_engine", True, "æœ¬åœ°è¿‡æ»¤å¼•æ“åˆå§‹åŒ–æ­£å¸¸")
            
        except Exception as e:
            import traceback
            error_msg = f"é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            self.log_test_result("1.3.1_local_filter_engine", False, error_msg)
    
    async def test_1_3_2_graph_query_optimizer(self):
        """æµ‹è¯•1.3.2å›¾æŸ¥è¯¢ä¼˜åŒ–å™¨"""
        try:
            from services.graph_query_optimizer import GraphQueryOptimizer
            from services.graph_database import GraphDatabaseManager
            
            # åˆ›å»ºGraphDatabaseManagerå®ä¾‹
            graph_manager = GraphDatabaseManager(
                uri="bolt://localhost:7687",
                username="neo4j",
                password="password"
            )
            
            # åˆ›å»ºä¼˜åŒ–å™¨
            optimizer = GraphQueryOptimizer(graph_manager)
            
            # æµ‹è¯•åŸºæœ¬å±æ€§
            # æµ‹è¯•ä¼˜åŒ–å™¨çš„åŸºæœ¬å±æ€§
            assert optimizer is not None
            assert hasattr(optimizer, 'graph_manager')
            assert hasattr(optimizer, 'query_templates')
            
            self.log_test_result("1.3.2_graph_query_optimizer", True, "å›¾æŸ¥è¯¢ä¼˜åŒ–å™¨åˆå§‹åŒ–æ­£å¸¸")
            
        except Exception as e:
            import traceback
            error_msg = f"é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            self.log_test_result("1.3.2_graph_query_optimizer", False, error_msg)
    
    async def test_end_to_end_integration(self):
        """ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""
        try:
            # æ¨¡æ‹Ÿå®Œæ•´çš„æ•°æ®æµ
            from services.falco_log_parser import FalcoLogParser
            from services.local_filter_engine import LocalFilterEngine
            from config.filter_engine_config import FilterEngineConfig
            
            # 1. è§£ææ—¥å¿—
            with tempfile.NamedTemporaryFile(mode='w', suffix='.log', delete=False) as f:
                log_path = f.name
            
            parser = FalcoLogParser(log_path)
            test_log = {
                "time": "2024-01-01T10:00:00.000000000Z",
                "rule": "Suspicious network activity",
                "priority": "Warning",
                "output": "Unexpected network connection detected",
                "output_fields": {
                    "fd.rip": "192.168.1.100",
                    "proc.name": "suspicious_proc"
                }
            }
            
            event = parser.parse_event(json.dumps(test_log))
            
            # 2. è¿‡æ»¤å¤„ç†
            config = FilterEngineConfig()
            engine = LocalFilterEngine(config)
            
            # æµ‹è¯•äº‹ä»¶å¤„ç†æµç¨‹
            assert event is not None
            assert hasattr(event, 'rule_name')
            
            self.log_test_result("end_to_end_integration", True, "ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            self.log_test_result("end_to_end_integration", False, f"é”™è¯¯: {str(e)}")
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("\n=== å¼€å§‹ç»¼åˆé›†æˆæµ‹è¯• ===")
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("\n" + "="*60)
        
        # è¿è¡Œå„æ¨¡å—æµ‹è¯•
        test_methods = [
            self.test_1_1_infrastructure,
            self.test_1_2_1_falco_log_parser,
            self.test_1_2_2_graph_database,
            self.test_1_2_3_log_volume_controller,
            self.test_1_3_1_local_filter_engine,
            self.test_1_3_2_graph_query_optimizer,
            self.test_end_to_end_integration
        ]
        
        for test_method in test_methods:
            try:
                await test_method()
                print(f"âœ“ {test_method.__name__}")
            except Exception as e:
                print(f"âœ— {test_method.__name__}: {str(e)}")
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_report()
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("=== ç»¼åˆæµ‹è¯•æŠ¥å‘Š ===")
        print(f"æ€»æµ‹è¯•æ•°: {self.total_tests}")
        print(f"é€šè¿‡: {self.passed_tests}")
        print(f"å¤±è´¥: {self.failed_tests}")
        print(f"æˆåŠŸç‡: {(self.passed_tests/self.total_tests*100):.1f}%")
        
        print("\nè¯¦ç»†ç»“æœ:")
        for module, result in self.test_results.items():
            status = "âœ“ é€šè¿‡" if result['success'] else "âœ— å¤±è´¥"
            print(f"  {module}: {status}")
            if result['details']:
                print(f"    è¯¦æƒ…: {result['details']}")
        
        # ç”Ÿæˆå»ºè®®
        if self.failed_tests > 0:
            print("\n=== ä¿®å¤å»ºè®® ===")
            for module, result in self.test_results.items():
                if not result['success']:
                    print(f"â€¢ {module}: {result['details']}")
        else:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å—å¼€å‘è´¨é‡è‰¯å¥½ã€‚")
        
        print("\n" + "="*60)


async def main():
    """ä¸»å‡½æ•°"""
    runner = ComprehensiveTestRunner()
    await runner.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())